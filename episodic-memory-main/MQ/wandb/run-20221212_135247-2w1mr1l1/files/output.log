---- Creamos un ViT ----
---- Creamos un ViT ----
---- Creamos un ViT ----
---- Creamos un ViT ----
---- Creamos un ViT ----
/home/s5091217/.local/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
Train loss (epoch 0):  loss: 6.4930 loss_cls_dec: 5.5052 loss_reg_dec: 0.3770 loss_action: 0.6853 loss_start: 0.6858 loss_end: 0.6749 loss_bd_adjust: 0.2016
Val loss (epoch 0):  loss: 5.8834 loss_cls_dec: 4.8830 loss_reg_dec: 0.3871 loss_action: 0.6707 loss_start: 0.6617 loss_end: 0.6377 loss_bd_adjust: 0.2193
2022-12-12 13:53:59.855560
2022-12-12 13:54:00.573791
The best model up to now is from Epoch 0
Train loss (epoch 1):  loss: 5.8551 loss_cls_dec: 4.9244 loss_reg_dec: 0.3547 loss_action: 0.6704 loss_start: 0.6621 loss_end: 0.6450 loss_bd_adjust: 0.1805
Val loss (epoch 1):  loss: 5.7797 loss_cls_dec: 4.8009 loss_reg_dec: 0.3804 loss_action: 0.6641 loss_start: 0.6497 loss_end: 0.6294 loss_bd_adjust: 0.2098
2022-12-12 13:55:07.606000
2022-12-12 13:55:08.382004
The best model up to now is from Epoch 1
Train loss (epoch 2):  loss: 5.7880 loss_cls_dec: 4.8724 loss_reg_dec: 0.3496 loss_action: 0.6654 loss_start: 0.6560 loss_end: 0.6393 loss_bd_adjust: 0.1738
Val loss (epoch 2):  loss: 5.7379 loss_cls_dec: 4.7742 loss_reg_dec: 0.3767 loss_action: 0.6588 loss_start: 0.6475 loss_end: 0.6276 loss_bd_adjust: 0.2002
2022-12-12 13:56:16.111632
2022-12-12 13:56:16.835710
The best model up to now is from Epoch 2
Train loss (epoch 3):  loss: 5.7396 loss_cls_dec: 4.8403 loss_reg_dec: 0.3470 loss_action: 0.6577 loss_start: 0.6473 loss_end: 0.6301 loss_bd_adjust: 0.1653
Val loss (epoch 3):  loss: 5.7219 loss_cls_dec: 4.7645 loss_reg_dec: 0.3767 loss_action: 0.6505 loss_start: 0.6427 loss_end: 0.6225 loss_bd_adjust: 0.1975
2022-12-12 13:57:21.270680
2022-12-12 13:57:22.005321
The best model up to now is from Epoch 3
Train loss (epoch 4):  loss: 5.6800 loss_cls_dec: 4.7931 loss_reg_dec: 0.3448 loss_action: 0.6459 loss_start: 0.6344 loss_end: 0.6187 loss_bd_adjust: 0.1622
Val loss (epoch 4):  loss: 5.7186 loss_cls_dec: 4.7626 loss_reg_dec: 0.3765 loss_action: 0.6465 loss_start: 0.6487 loss_end: 0.6268 loss_bd_adjust: 0.1951
2022-12-12 13:58:35.384008
2022-12-12 13:58:36.091117
The best model up to now is from Epoch 4
Train loss (epoch 5):  loss: 5.5839 loss_cls_dec: 4.7124 loss_reg_dec: 0.3404 loss_action: 0.6407 loss_start: 0.6197 loss_end: 0.6035 loss_bd_adjust: 0.1582
Val loss (epoch 5):  loss: 5.7054 loss_cls_dec: 4.7502 loss_reg_dec: 0.3776 loss_action: 0.6437 loss_start: 0.6546 loss_end: 0.6299 loss_bd_adjust: 0.1920
2022-12-12 13:59:48.946973
2022-12-12 13:59:49.639048
The best model up to now is from Epoch 5
Train loss (epoch 6):  loss: 5.4583 loss_cls_dec: 4.6019 loss_reg_dec: 0.3369 loss_action: 0.6300 loss_start: 0.6047 loss_end: 0.5888 loss_bd_adjust: 0.1548
Val loss (epoch 6):  loss: 5.6709 loss_cls_dec: 4.7048 loss_reg_dec: 0.3820 loss_action: 0.6612 loss_start: 0.6674 loss_end: 0.6441 loss_bd_adjust: 0.1894
2022-12-12 14:00:58.624522
2022-12-12 14:00:59.336033
The best model up to now is from Epoch 6
Train loss (epoch 7):  loss: 5.2388 loss_cls_dec: 4.3950 loss_reg_dec: 0.3341 loss_action: 0.6238 loss_start: 0.5910 loss_end: 0.5747 loss_bd_adjust: 0.1518
Val loss (epoch 7):  loss: 5.4830 loss_cls_dec: 4.5190 loss_reg_dec: 0.3826 loss_action: 0.6417 loss_start: 0.6725 loss_end: 0.6475 loss_bd_adjust: 0.1890
2022-12-12 14:02:05.083796
2022-12-12 14:02:05.800356
The best model up to now is from Epoch 7
Train loss (epoch 8):  loss: 4.9639 loss_cls_dec: 4.1310 loss_reg_dec: 0.3311 loss_action: 0.6154 loss_start: 0.5782 loss_end: 0.5586 loss_bd_adjust: 0.1514
Val loss (epoch 8):  loss: 5.3031 loss_cls_dec: 4.3208 loss_reg_dec: 0.3916 loss_action: 0.6421 loss_start: 0.6801 loss_end: 0.6593 loss_bd_adjust: 0.1944
2022-12-12 14:03:15.736152
2022-12-12 14:03:16.499651
The best model up to now is from Epoch 8
Train loss (epoch 9):  loss: 4.6712 loss_cls_dec: 3.8516 loss_reg_dec: 0.3283 loss_action: 0.6071 loss_start: 0.5612 loss_end: 0.5401 loss_bd_adjust: 0.1496
Val loss (epoch 9):  loss: 5.2148 loss_cls_dec: 4.2125 loss_reg_dec: 0.3938 loss_action: 0.6502 loss_start: 0.7300 loss_end: 0.7160 loss_bd_adjust: 0.1893
2022-12-12 14:04:22.748455
2022-12-12 14:04:23.462494
The best model up to now is from Epoch 9
Train loss (epoch 10):  loss: 4.4263 loss_cls_dec: 3.6184 loss_reg_dec: 0.3245 loss_action: 0.5999 loss_start: 0.5507 loss_end: 0.5296 loss_bd_adjust: 0.1473
Val loss (epoch 10):  loss: 5.1328 loss_cls_dec: 4.1108 loss_reg_dec: 0.4002 loss_action: 0.6697 loss_start: 0.7463 loss_end: 0.7323 loss_bd_adjust: 0.1921
2022-12-12 14:05:31.995525
2022-12-12 14:05:32.758444
The best model up to now is from Epoch 10
Train loss (epoch 11):  loss: 4.2111 loss_cls_dec: 3.4169 loss_reg_dec: 0.3217 loss_action: 0.5916 loss_start: 0.5347 loss_end: 0.5082 loss_bd_adjust: 0.1457
Val loss (epoch 11):  loss: 5.0744 loss_cls_dec: 4.0451 loss_reg_dec: 0.3980 loss_action: 0.6517 loss_start: 0.7644 loss_end: 0.7767 loss_bd_adjust: 0.1927
2022-12-12 14:06:39.936231
2022-12-12 14:06:40.643707
The best model up to now is from Epoch 11
Train loss (epoch 12):  loss: 3.9888 loss_cls_dec: 3.2059 loss_reg_dec: 0.3167 loss_action: 0.5879 loss_start: 0.5218 loss_end: 0.4972 loss_bd_adjust: 0.1447
Val loss (epoch 12):  loss: 4.9516 loss_cls_dec: 3.9180 loss_reg_dec: 0.4030 loss_action: 0.6552 loss_start: 0.7781 loss_end: 0.7641 loss_bd_adjust: 0.1912
2022-12-12 14:07:46.077876
2022-12-12 14:07:46.820444
The best model up to now is from Epoch 12
Train loss (epoch 13):  loss: 3.7844 loss_cls_dec: 3.0147 loss_reg_dec: 0.3128 loss_action: 0.5788 loss_start: 0.5100 loss_end: 0.4780 loss_bd_adjust: 0.1435
Val loss (epoch 13):  loss: 5.0398 loss_cls_dec: 3.9829 loss_reg_dec: 0.4089 loss_action: 0.6479 loss_start: 0.8016 loss_end: 0.8286 loss_bd_adjust: 0.1925
2022-12-12 14:08:55.728412
Train loss (epoch 14):  loss: 3.5875 loss_cls_dec: 2.8295 loss_reg_dec: 0.3090 loss_action: 0.5764 loss_start: 0.4976 loss_end: 0.4652 loss_bd_adjust: 0.1412
Val loss (epoch 14):  loss: 4.9664 loss_cls_dec: 3.9053 loss_reg_dec: 0.4089 loss_action: 0.6548 loss_start: 0.8144 loss_end: 0.8380 loss_bd_adjust: 0.1907
2022-12-12 14:10:04.204244
Train loss (epoch 15):  loss: 3.2376 loss_cls_dec: 2.5075 loss_reg_dec: 0.2977 loss_action: 0.5672 loss_start: 0.4787 loss_end: 0.4415 loss_bd_adjust: 0.1349
Val loss (epoch 15):  loss: 4.8711 loss_cls_dec: 3.8117 loss_reg_dec: 0.4096 loss_action: 0.6570 loss_start: 0.8145 loss_end: 0.8258 loss_bd_adjust: 0.1903
2022-12-12 14:11:10.827399
2022-12-12 14:11:11.698687
The best model up to now is from Epoch 15
Train loss (epoch 16):  loss: 3.1191 loss_cls_dec: 2.3993 loss_reg_dec: 0.2927 loss_action: 0.5615 loss_start: 0.4732 loss_end: 0.4369 loss_bd_adjust: 0.1327
Val loss (epoch 16):  loss: 4.9033 loss_cls_dec: 3.8280 loss_reg_dec: 0.4117 loss_action: 0.6592 loss_start: 0.8481 loss_end: 0.8570 loss_bd_adjust: 0.1908
2022-12-12 14:12:18.262541
Train loss (epoch 17):  loss: 3.0418 loss_cls_dec: 2.3290 loss_reg_dec: 0.2907 loss_action: 0.5569 loss_start: 0.4691 loss_end: 0.4305 loss_bd_adjust: 0.1308
Val loss (epoch 17):  loss: 4.9454 loss_cls_dec: 3.8627 loss_reg_dec: 0.4145 loss_action: 0.6627 loss_start: 0.8502 loss_end: 0.8663 loss_bd_adjust: 0.1924
2022-12-12 14:13:23.097578
Train loss (epoch 18):  loss: 2.9946 loss_cls_dec: 2.2864 loss_reg_dec: 0.2889 loss_action: 0.5532 loss_start: 0.4666 loss_end: 0.4274 loss_bd_adjust: 0.1299
Val loss (epoch 18):  loss: 4.9207 loss_cls_dec: 3.8438 loss_reg_dec: 0.4156 loss_action: 0.6639 loss_start: 0.8288 loss_end: 0.8497 loss_bd_adjust: 0.1929
2022-12-12 14:14:32.746314
Train loss (epoch 19):  loss: 2.9522 loss_cls_dec: 2.2488 loss_reg_dec: 0.2864 loss_action: 0.5500 loss_start: 0.4651 loss_end: 0.4259 loss_bd_adjust: 0.1288
Val loss (epoch 19):  loss: 4.9628 loss_cls_dec: 3.8747 loss_reg_dec: 0.4166 loss_action: 0.6674 loss_start: 0.8550 loss_end: 0.8759 loss_bd_adjust: 0.1918
2022-12-12 14:15:39.810810
Train loss (epoch 20):  loss: 2.9097 loss_cls_dec: 2.2079 loss_reg_dec: 0.2855 loss_action: 0.5558 loss_start: 0.4637 loss_end: 0.4232 loss_bd_adjust: 0.1278
Val loss (epoch 20):  loss: 4.9657 loss_cls_dec: 3.8765 loss_reg_dec: 0.4175 loss_action: 0.6664 loss_start: 0.8558 loss_end: 0.8764 loss_bd_adjust: 0.1921
2022-12-12 14:16:47.412177
Train loss (epoch 21):  loss: 2.8573 loss_cls_dec: 2.1614 loss_reg_dec: 0.2832 loss_action: 0.5493 loss_start: 0.4592 loss_end: 0.4195 loss_bd_adjust: 0.1272
Val loss (epoch 21):  loss: 4.9675 loss_cls_dec: 3.8725 loss_reg_dec: 0.4190 loss_action: 0.6688 loss_start: 0.8593 loss_end: 0.8866 loss_bd_adjust: 0.1930
2022-12-12 14:17:53.006370
Train loss (epoch 22):  loss: 2.8202 loss_cls_dec: 2.1277 loss_reg_dec: 0.2813 loss_action: 0.5472 loss_start: 0.4592 loss_end: 0.4181 loss_bd_adjust: 0.1263
Val loss (epoch 22):  loss: 5.0130 loss_cls_dec: 3.9096 loss_reg_dec: 0.4214 loss_action: 0.6723 loss_start: 0.8704 loss_end: 0.9042 loss_bd_adjust: 0.1927
2022-12-12 14:19:01.630866
Train loss (epoch 23):  loss: 2.7872 loss_cls_dec: 2.0974 loss_reg_dec: 0.2800 loss_action: 0.5474 loss_start: 0.4559 loss_end: 0.4147 loss_bd_adjust: 0.1262
Val loss (epoch 23):  loss: 5.0339 loss_cls_dec: 3.9279 loss_reg_dec: 0.4216 loss_action: 0.6740 loss_start: 0.8700 loss_end: 0.9093 loss_bd_adjust: 0.1938
2022-12-12 14:20:11.101793
Train loss (epoch 24):  loss: 2.7495 loss_cls_dec: 2.0632 loss_reg_dec: 0.2782 loss_action: 0.5445 loss_start: 0.4541 loss_end: 0.4128 loss_bd_adjust: 0.1258
Val loss (epoch 24):  loss: 5.0429 loss_cls_dec: 3.9370 loss_reg_dec: 0.4217 loss_action: 0.6746 loss_start: 0.8719 loss_end: 0.9096 loss_bd_adjust: 0.1931
2022-12-12 14:21:17.573179
Train loss (epoch 25):  loss: 2.7155 loss_cls_dec: 2.0312 loss_reg_dec: 0.2782 loss_action: 0.5458 loss_start: 0.4523 loss_end: 0.4085 loss_bd_adjust: 0.1249
Val loss (epoch 25):  loss: 5.0473 loss_cls_dec: 3.9418 loss_reg_dec: 0.4240 loss_action: 0.6738 loss_start: 0.8626 loss_end: 0.9033 loss_bd_adjust: 0.1936
2022-12-12 14:22:26.443552
Train loss (epoch 26):  loss: 2.6839 loss_cls_dec: 2.0038 loss_reg_dec: 0.2758 loss_action: 0.5438 loss_start: 0.4492 loss_end: 0.4058 loss_bd_adjust: 0.1245
Val loss (epoch 26):  loss: 5.0596 loss_cls_dec: 3.9435 loss_reg_dec: 0.4244 loss_action: 0.6766 loss_start: 0.8839 loss_end: 0.9292 loss_bd_adjust: 0.1939
2022-12-12 14:23:33.627611
Train loss (epoch 27):  loss: 2.6508 loss_cls_dec: 1.9723 loss_reg_dec: 0.2751 loss_action: 0.5407 loss_start: 0.4479 loss_end: 0.4046 loss_bd_adjust: 0.1247
Val loss (epoch 27):  loss: 5.0530 loss_cls_dec: 3.9437 loss_reg_dec: 0.4248 loss_action: 0.6734 loss_start: 0.8709 loss_end: 0.9084 loss_bd_adjust: 0.1940
2022-12-12 14:24:41.760380
Train loss (epoch 28):  loss: 2.6084 loss_cls_dec: 1.9342 loss_reg_dec: 0.2733 loss_action: 0.5395 loss_start: 0.4453 loss_end: 0.4016 loss_bd_adjust: 0.1235
Val loss (epoch 28):  loss: 5.1074 loss_cls_dec: 3.9824 loss_reg_dec: 0.4264 loss_action: 0.6773 loss_start: 0.9014 loss_end: 0.9440 loss_bd_adjust: 0.1940
2022-12-12 14:25:48.565869
Train loss (epoch 29):  loss: 2.5849 loss_cls_dec: 1.9128 loss_reg_dec: 0.2721 loss_action: 0.5396 loss_start: 0.4437 loss_end: 0.3993 loss_bd_adjust: 0.1235
Val loss (epoch 29):  loss: 5.0923 loss_cls_dec: 3.9646 loss_reg_dec: 0.4273 loss_action: 0.6801 loss_start: 0.8972 loss_end: 0.9511 loss_bd_adjust: 0.1946
2022-12-12 14:26:55.247679
Training finishes!